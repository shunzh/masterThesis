In this thesis, we followed an earlier work on modular inverse reinforcement
learning. We proposed a new modular inverse reinforcement
learning algorithm, and applied it to collected human subjects' data to analyze
their behavior.
The experimental results show that modular reinforcement learning can explain
human's navigation behavior. By our evaluation metrics, this method is better
than the other baseline assumptions.
We still notice a limitation of our evaluation that the environment is
inherently modularized. We propose that our modularization approach can be
applied to real world problems, like driving. This remains to be evaluated in
the future work.

We have discussed in the literature review that modular approach is just one way to combine multiple
sub-MDPs. There are other assumptions that can be evaluated in the future work.
For example, scheduling between
different modules, with only one active at one time. This is close to the skill
switching method \cite{konidaris2009skill}. However, we adopt the
weighted sum approach because this is more reasonable for human behavior. When a
human tries to collect targets while avoiding obstacles, these two modules are
expected to be both active. A scheduling approach may yield frequent oscillation
between these two modules.

Static combination of modules throughout a task is another assumption that
should be removed in the future work. Parameters may be dynamic and different from
state to state.  However, with such an assumption we need to learn a mapping
from state to parameters. In this case, the curse of dimensionality still exists,
and inverse learning would be difficult.

So far, we only used the motion data of human subjects. There is also gaze data
collected but not used. Gazes are the points that human subjects are looking at
at a time step, which indicate humans' attention. This is actually a useful
information on how human combines different modules. When a human is paying
attention to a module, it is reasonable to assume that his action would be
affected mainly by this module.

In sum, we show in this thesis that modular reinforcement learning is a
promising explanation for human's navigation behavior. It is of interest to see
its analysis on different humans' behavior, and using the recovered parameters
for a learning agent to tackle similar tasks.
